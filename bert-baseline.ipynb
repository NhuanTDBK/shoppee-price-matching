{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T08:42:43.251511Z",
     "iopub.status.busy": "2021-03-18T08:42:43.250888Z",
     "iopub.status.idle": "2021-03-18T08:42:48.925948Z",
     "shell.execute_reply": "2021-03-18T08:42:48.926669Z"
    },
    "papermill": {
     "duration": 5.686239,
     "end_time": "2021-03-18T08:42:48.927079",
     "exception": false,
     "start_time": "2021-03-18T08:42:43.240840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import backend as K\n",
    "copyfile(src = \"../input/shopee-external-models/tokenization.py\", dst = \"../working/tokenization.py\")\n",
    "import tokenization\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T08:42:48.946650Z",
     "iopub.status.busy": "2021-03-18T08:42:48.945401Z",
     "iopub.status.idle": "2021-03-18T08:42:48.948230Z",
     "shell.execute_reply": "2021-03-18T08:42:48.947399Z"
    },
    "papermill": {
     "duration": 0.015357,
     "end_time": "2021-03-18T08:42:48.948387",
     "exception": false,
     "start_time": "2021-03-18T08:42:48.933030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "# Seed\n",
    "SEED = 123\n",
    "# Verbosity\n",
    "VERBOSE = 1\n",
    "LR = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T08:42:49.009888Z",
     "iopub.status.busy": "2021-03-18T08:42:48.965871Z",
     "iopub.status.idle": "2021-03-18T13:31:14.429824Z",
     "shell.execute_reply": "2021-03-18T13:31:14.429333Z"
    },
    "papermill": {
     "duration": 17305.476134,
     "end_time": "2021-03-18T13:31:14.429945",
     "exception": false,
     "start_time": "2021-03-18T08:42:48.953811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 11014 classes\n",
      "Epoch 1/25\n",
      "718/718 [==============================] - 722s 960ms/step - loss: 23.9817 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.4543 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 23.45433, saving model to Bert_123.h5\n",
      "Epoch 2/25\n",
      "718/718 [==============================] - 685s 955ms/step - loss: 22.8442 - sparse_categorical_accuracy: 2.1435e-06 - val_loss: 22.0693 - val_sparse_categorical_accuracy: 9.7319e-04\n",
      "\n",
      "Epoch 00002: val_loss improved from 23.45433 to 22.06927, saving model to Bert_123.h5\n",
      "Epoch 3/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 20.7200 - sparse_categorical_accuracy: 0.0042 - val_loss: 20.7647 - val_sparse_categorical_accuracy: 0.0127\n",
      "\n",
      "Epoch 00003: val_loss improved from 22.06927 to 20.76471, saving model to Bert_123.h5\n",
      "Epoch 4/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 18.7384 - sparse_categorical_accuracy: 0.0159 - val_loss: 19.9690 - val_sparse_categorical_accuracy: 0.0222\n",
      "\n",
      "Epoch 00004: val_loss improved from 20.76471 to 19.96896, saving model to Bert_123.h5\n",
      "Epoch 5/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 17.6777 - sparse_categorical_accuracy: 0.0317 - val_loss: 19.3635 - val_sparse_categorical_accuracy: 0.0303\n",
      "\n",
      "Epoch 00005: val_loss improved from 19.96896 to 19.36350, saving model to Bert_123.h5\n",
      "Epoch 6/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 16.9964 - sparse_categorical_accuracy: 0.0374 - val_loss: 18.6961 - val_sparse_categorical_accuracy: 0.0411\n",
      "\n",
      "Epoch 00006: val_loss improved from 19.36350 to 18.69612, saving model to Bert_123.h5\n",
      "Epoch 7/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 15.2931 - sparse_categorical_accuracy: 0.0574 - val_loss: 18.1066 - val_sparse_categorical_accuracy: 0.0513\n",
      "\n",
      "Epoch 00007: val_loss improved from 18.69612 to 18.10656, saving model to Bert_123.h5\n",
      "Epoch 8/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 13.9004 - sparse_categorical_accuracy: 0.0818 - val_loss: 17.8998 - val_sparse_categorical_accuracy: 0.0527\n",
      "\n",
      "Epoch 00008: val_loss improved from 18.10656 to 17.89984, saving model to Bert_123.h5\n",
      "Epoch 9/25\n",
      "718/718 [==============================] - 685s 955ms/step - loss: 13.0701 - sparse_categorical_accuracy: 0.1013 - val_loss: 17.0244 - val_sparse_categorical_accuracy: 0.0748\n",
      "\n",
      "Epoch 00009: val_loss improved from 17.89984 to 17.02444, saving model to Bert_123.h5\n",
      "Epoch 10/25\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 11.7211 - sparse_categorical_accuracy: 0.1342 - val_loss: 16.5329 - val_sparse_categorical_accuracy: 0.0865\n",
      "\n",
      "Epoch 00010: val_loss improved from 17.02444 to 16.53293, saving model to Bert_123.h5\n",
      "Epoch 11/25\n",
      "718/718 [==============================] - 685s 955ms/step - loss: 10.5022 - sparse_categorical_accuracy: 0.1708 - val_loss: 16.1373 - val_sparse_categorical_accuracy: 0.1003\n",
      "\n",
      "Epoch 00011: val_loss improved from 16.53293 to 16.13726, saving model to Bert_123.h5\n",
      "Epoch 12/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 9.3680 - sparse_categorical_accuracy: 0.2145 - val_loss: 15.7750 - val_sparse_categorical_accuracy: 0.1104\n",
      "\n",
      "Epoch 00012: val_loss improved from 16.13726 to 15.77503, saving model to Bert_123.h5\n",
      "Epoch 13/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 8.2899 - sparse_categorical_accuracy: 0.2653 - val_loss: 15.4487 - val_sparse_categorical_accuracy: 0.1209\n",
      "\n",
      "Epoch 00013: val_loss improved from 15.77503 to 15.44874, saving model to Bert_123.h5\n",
      "Epoch 14/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 7.3923 - sparse_categorical_accuracy: 0.3114 - val_loss: 16.0146 - val_sparse_categorical_accuracy: 0.0943\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 15.44874\n",
      "Epoch 15/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 7.0510 - sparse_categorical_accuracy: 0.3297 - val_loss: 14.8861 - val_sparse_categorical_accuracy: 0.1397\n",
      "\n",
      "Epoch 00015: val_loss improved from 15.44874 to 14.88609, saving model to Bert_123.h5\n",
      "Epoch 16/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 5.5769 - sparse_categorical_accuracy: 0.4330 - val_loss: 14.6601 - val_sparse_categorical_accuracy: 0.1453\n",
      "\n",
      "Epoch 00016: val_loss improved from 14.88609 to 14.66013, saving model to Bert_123.h5\n",
      "Epoch 17/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 4.7216 - sparse_categorical_accuracy: 0.5047 - val_loss: 14.4417 - val_sparse_categorical_accuracy: 0.1516\n",
      "\n",
      "Epoch 00017: val_loss improved from 14.66013 to 14.44173, saving model to Bert_123.h5\n",
      "Epoch 18/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 4.0958 - sparse_categorical_accuracy: 0.5577 - val_loss: 14.2446 - val_sparse_categorical_accuracy: 0.1572\n",
      "\n",
      "Epoch 00018: val_loss improved from 14.44173 to 14.24463, saving model to Bert_123.h5\n",
      "Epoch 19/25\n",
      "718/718 [==============================] - 686s 955ms/step - loss: 3.5529 - sparse_categorical_accuracy: 0.6125 - val_loss: 14.0934 - val_sparse_categorical_accuracy: 0.1627\n",
      "\n",
      "Epoch 00019: val_loss improved from 14.24463 to 14.09341, saving model to Bert_123.h5\n",
      "Epoch 20/25\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 3.5371 - sparse_categorical_accuracy: 0.6198 - val_loss: 13.9239 - val_sparse_categorical_accuracy: 0.1702\n",
      "\n",
      "Epoch 00020: val_loss improved from 14.09341 to 13.92386, saving model to Bert_123.h5\n",
      "Epoch 21/25\n",
      "718/718 [==============================] - 685s 955ms/step - loss: 2.7445 - sparse_categorical_accuracy: 0.7072 - val_loss: 13.6779 - val_sparse_categorical_accuracy: 0.1866\n",
      "\n",
      "Epoch 00021: val_loss improved from 13.92386 to 13.67789, saving model to Bert_123.h5\n",
      "Epoch 22/25\n",
      "718/718 [==============================] - 685s 955ms/step - loss: 2.0066 - sparse_categorical_accuracy: 0.8245 - val_loss: 13.5399 - val_sparse_categorical_accuracy: 0.1969\n",
      "\n",
      "Epoch 00022: val_loss improved from 13.67789 to 13.53989, saving model to Bert_123.h5\n",
      "Epoch 23/25\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 1.5464 - sparse_categorical_accuracy: 0.8932 - val_loss: 13.4401 - val_sparse_categorical_accuracy: 0.2056\n",
      "\n",
      "Epoch 00023: val_loss improved from 13.53989 to 13.44014, saving model to Bert_123.h5\n",
      "Epoch 24/25\n",
      "718/718 [==============================] - 685s 955ms/step - loss: 1.2086 - sparse_categorical_accuracy: 0.9398 - val_loss: 13.3403 - val_sparse_categorical_accuracy: 0.2134\n",
      "\n",
      "Epoch 00024: val_loss improved from 13.44014 to 13.34028, saving model to Bert_123.h5\n",
      "Epoch 25/25\n",
      "718/718 [==============================] - 685s 954ms/step - loss: 0.9168 - sparse_categorical_accuracy: 0.9673 - val_loss: 13.2656 - val_sparse_categorical_accuracy: 0.2155\n",
      "\n",
      "Epoch 00025: val_loss improved from 13.34028 to 13.26557, saving model to Bert_123.h5\n"
     ]
    }
   ],
   "source": [
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "def read_and_preprocess():\n",
    "    df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "    tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "    df['matches'] = df['label_group'].map(tmp)\n",
    "    df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
    "    encoder = LabelEncoder()\n",
    "    df['label_group'] = encoder.fit_transform(df['label_group'])\n",
    "    N_CLASSES = df['label_group'].nunique()\n",
    "    print(f'We have {N_CLASSES} classes')\n",
    "    x_train, x_val, y_train, y_val = train_test_split(df[['title']], df['label_group'], shuffle = True, stratify = df['label_group'], random_state = SEED, test_size = 0.33)\n",
    "    return df, N_CLASSES, x_train, x_val, y_train, y_val\n",
    "\n",
    "# Return tokens, masks and segments from a text array or series\n",
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
    "\n",
    "\n",
    "# Arcmarginproduct class keras layer\n",
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output\n",
    "\n",
    "# Function to build bert model\n",
    "def build_bert_model(bert_layer, max_len = 512):\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = N_CLASSES, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'label')\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    x = margin([clf_output, label])\n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "    model = tf.keras.models.Model(inputs = [input_word_ids, input_mask, segment_ids, label], outputs = [output])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr = LR),\n",
    "                  loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n",
    "                  metrics = [tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    return model\n",
    "\n",
    "def load_train_and_evaluate(x_train, x_val, y_train, y_val):\n",
    "    seed_everything(SEED)\n",
    "    # Load BERT from the Tensorflow Hub\n",
    "    module_url = \"../input/shopee-external-models/bert_en_uncased_L-24_H-1024_A-16_1\"\n",
    "    bert_layer = hub.KerasLayer(module_url, trainable = True)\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "    x_train = bert_encode(x_train['title'].values, tokenizer, max_len = 70)\n",
    "    x_val = bert_encode(x_val['title'].values, tokenizer, max_len = 70)\n",
    "    y_train = y_train.values\n",
    "    y_val = y_val.values\n",
    "    # Add targets to train and val\n",
    "    x_train = (x_train[0], x_train[1], x_train[2], y_train)\n",
    "    x_val = (x_val[0], x_val[1], x_val[2], y_val)\n",
    "    bert_model = build_bert_model(bert_layer, max_len = 70)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'Bert_{SEED}.h5', \n",
    "                                                    monitor = 'val_loss', \n",
    "                                                    verbose = VERBOSE, \n",
    "                                                    save_best_only = True,\n",
    "                                                    save_weights_only = True, \n",
    "                                                    mode = 'min')\n",
    "    history = bert_model.fit(x_train, y_train,\n",
    "                             validation_data = (x_val, y_val),\n",
    "                             epochs = EPOCHS, \n",
    "                             callbacks = [checkpoint],\n",
    "                             batch_size = BATCH_SIZE,\n",
    "                             verbose = VERBOSE)\n",
    "    \n",
    "    \n",
    "\n",
    "df, N_CLASSES, x_train, x_val, y_train, y_val = read_and_preprocess()\n",
    "load_train_and_evaluate(x_train, x_val, y_train, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17326.241293,
   "end_time": "2021-03-18T13:31:24.598618",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-18T08:42:38.357325",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
